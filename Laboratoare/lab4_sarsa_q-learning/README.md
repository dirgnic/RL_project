# ğŸ§  Laborator RL â€” SARSA vs Q-Learning

## ğŸ“˜ Scopul laboratorului
Acest laborator urmÄƒreÈ™te Ã®nÈ›elegerea diferenÈ›elor conceptuale È™i practice dintre doi algoritmi fundamentali de Reinforcement Learning:

- **SARSA** (State-Action-Reward-State-Action) â€“ algoritm *on-policy*
- **Q-Learning** â€“ algoritm *off-policy*

Prin parcurgerea laboratorului, vei Ã®nvÄƒÈ›a:
- cum funcÈ›ioneazÄƒ cele douÄƒ metode de actualizare Q-value;
- cum se antreneazÄƒ agenÈ›ii pe acelaÈ™i mediu;
- cum diferÄƒ comportamentul rezultat;
- cum sÄƒ vizualizezi traiectoriile È™i sÄƒ compari politicile Ã®nvÄƒÈ›ate.

---

## ğŸ§© Medii de lucru

### ğŸªœ CliffWalking-v0
Vom folosi mediul `CliffWalking-v0` din biblioteca `gymnasium`, deoarece ilustreazÄƒ perfect diferenÈ›ele de comportament dintre SARSA È™i Q-Learning:
- agentul trebuie sÄƒ ajungÄƒ de la **S (Start)** la **G (Goal)**;
- zona **# (Cliff)** oferÄƒ penalizare mare (`âˆ’100`);
- pas normal = `âˆ’1`.

SARSA tinde sÄƒ evite prÄƒpastia (strategie sigurÄƒ),  
Q-Learning cautÄƒ traseul optim teoretic, dar riscÄƒ penalizÄƒri.

![cliff walk](images/cliff_walking.gif)

---

### ğŸ›¸ LunarLander-v2
DupÄƒ Ã®nÈ›elegerea conceptelor de bazÄƒ, vom trece la un mediu mai complex: **`LunarLander-v2`**, care face parte din categoria *Box2D environments*.

Scopul este de a ateriza o navetÄƒ spaÈ›ialÄƒ Ã®ntre doi markeri, controlÃ¢nd motoarele laterale È™i principale, astfel Ã®ncÃ¢t:
- sÄƒ atingi solul cu o vitezÄƒ È™i un unghi sigure,
- sÄƒ nu te rÄƒstorni sau sÄƒ te prÄƒbuÈ™eÈ™ti,
- sÄƒ optimizezi consumul de combustibil.

**Caracteristici principale:**
- **SpaÈ›iu de stare continuu:** 8 dimensiuni (poziÈ›ie, vitezÄƒ, unghi, contact cu solul);
- **SpaÈ›iu de acÈ›iune discret:** 4 acÈ›iuni (no thrust, main engine, left engine, right engine);
- **Recompense:**
  - +100 pÃ¢nÄƒ la +140 pentru aterizare corectÄƒ;
  - âˆ’100 dacÄƒ se prÄƒbuÈ™eÈ™te;
  - +10 pentru contact parÈ›ial;
  - penalizÄƒri pentru combustibil È™i miÈ™care excesivÄƒ.

Acest mediu necesitÄƒ **discretizarea spaÈ›iului de stÄƒri** pentru a putea fi abordat prin Q-Learning clasic, iar ulterior oferÄƒ o bunÄƒ tranziÈ›ie spre **Deep Q-Learning (DQL)**.

![lunar lander](images/lunar_lander.gif)

---

## âš™ï¸ Configurarea mediului de lucru



```bash
# CreeazÄƒ mediul
conda env create -f environment.yml

# Activare mediu
conda activate irl-lab4

# Instalare gym-box2d
conda install -c conda-forge gym-box2d
```
