{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7170cb91",
   "metadata": {},
   "source": [
    "# Lab 1 â€” Gymnasium Intro (cu un agent simplu, random, fÄƒrÄƒ algoritmi de RL)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f68bb1ff",
   "metadata": {},
   "source": [
    "## 1) Crearea mediului"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "953a2c2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gymnasium as gym\n",
    "\n",
    "env = gym.make(\"CartPole-v1\", render_mode=\"rgb_array\")\n",
    "obs, info = env.reset()\n",
    "type(obs), env.observation_space, env.action_space"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "faf38064",
   "metadata": {},
   "source": [
    "## 2) Agent random (CartPole)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61b29f37",
   "metadata": {},
   "source": [
    "## ðŸ—ï¸ Mediul CartPole-v1\n",
    "\n",
    "**CartPole** este unul dintre cele mai simple È™i mai utilizate medii din `gymnasium`, ideal pentru a Ã®nÈ›elege conceptele de *stare*, *acÈ›iune*, *recompensÄƒ* È™i *episoade*.  \n",
    "Scopul agentului este sÄƒ **menÈ›inÄƒ o barÄƒ verticalÄƒ echilibratÄƒ** pe un cÄƒrucior care se deplaseazÄƒ pe o linie orizontalÄƒ.\n",
    "\n",
    "---\n",
    "\n",
    "### âš™ï¸ Descrierea mediului\n",
    "\n",
    "- ðŸ§© **SpaÈ›iul de observaÈ›ie (`observation_space`)**  \n",
    "  Vector cu 4 valori continue:\n",
    "  1. PoziÈ›ia cÄƒruciorului *(cart position)*  \n",
    "  2. Viteza cÄƒruciorului *(cart velocity)*  \n",
    "  3. Unghiul barei *(pole angle)*  \n",
    "  4. Viteza unghiularÄƒ a barei *(pole angular velocity)*  \n",
    "\n",
    "  Exemplu: `[-0.005, 0.03, 0.012, -0.05]`\n",
    "\n",
    "- ðŸŽ® **SpaÈ›iul de acÈ›iuni (`action_space`)**  \n",
    "  Discret, cu douÄƒ posibile acÈ›iuni:\n",
    "  - `0` â†’ Ã®mpinge cÄƒruciorul spre stÃ¢nga  \n",
    "  - `1` â†’ Ã®mpinge cÄƒruciorul spre dreapta  \n",
    "\n",
    "- ðŸ† **RecompensÄƒ (`reward`)**  \n",
    "  +1 pentru fiecare pas Ã®n care bara rÄƒmÃ¢ne Ã®n poziÈ›ie stabilÄƒ.  \n",
    "  Episodul se terminÄƒ dacÄƒ bara cade prea mult (|angle| > 12Â°) sau dacÄƒ cÄƒruciorul pÄƒrÄƒseÈ™te zona permisÄƒ (|position| > 2.4).  \n",
    "\n",
    "- â±ï¸ **Durata maximÄƒ**  \n",
    "  500 de paÈ™i per episod (Ã®n versiunea `v1`).\n",
    "\n",
    "---\n",
    "\n",
    "### ðŸ“˜ DocumentaÈ›ie oficialÄƒ\n",
    "\n",
    "ðŸ”— [CartPole-v1 â€” Gymnasium Documentation](https://gymnasium.farama.org/environments/classic_control/cart_pole/)\n",
    "\n",
    "---\n",
    "\n",
    "### ðŸ’¬ Curiozitate\n",
    "\n",
    "Acesta este unul dintre primele exemple de RL!!! â€”  \n",
    "Ã®n anii â€™80â€“â€™90, agenÈ›i *Q-learning* È™i *Policy Gradient* erau antrenaÈ›i sÄƒ Ã®nveÈ›e echilibrul doar prin Ã®ncercÄƒri È™i recompense, fÄƒrÄƒ nicio informaÈ›ie explicitÄƒ despre fizicÄƒ.\n",
    "\n",
    "---\n",
    "\n",
    "**Obiectiv:**  \n",
    "> Agentul trebuie sÄƒ maximizeze recompensa totalÄƒ (sÄƒ È›inÄƒ bara echilibratÄƒ cÃ¢t mai mult timp).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "441990fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gymnasium as gym\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import animation\n",
    "from IPython.display import HTML\n",
    "\n",
    "env = gym.make(\"CartPole-v1\", render_mode=\"rgb_array\")\n",
    "obs, info = env.reset()\n",
    "frames = []\n",
    "\n",
    "for t in range(200):\n",
    "    action = env.action_space.sample()\n",
    "    obs, reward, terminated, truncated, info = env.step(action)\n",
    "    frames.append(env.render())\n",
    "    if terminated or truncated:\n",
    "        break\n",
    "env.close()\n",
    "\n",
    "# === Rezultat ===\n",
    "fig, ax = plt.subplots()\n",
    "im = ax.imshow(frames[0])\n",
    "ax.axis(\"off\")\n",
    "\n",
    "def update(frame):\n",
    "    im.set_data(frame)\n",
    "    return [im]\n",
    "\n",
    "ani = animation.FuncAnimation(fig, update, frames=frames, interval=50, blit=True)\n",
    "plt.close(fig) \n",
    "HTML(ani.to_jshtml())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09ba5211",
   "metadata": {},
   "source": [
    "## TODO\n",
    "1. InspectaÈ›i `observation_space`/`action_space` È™i explicaÈ›i semnificaÈ›ia lor.\n",
    "2. MÄƒriÈ›i episoadele È™i observaÈ›i efectul asupra reward-ului total.\n",
    "\n",
    "Vom discuta mult mai multe Ã®n laboratoarele viitoare."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rl-intro-lab1",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
